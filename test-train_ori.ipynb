{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nepoch,  0\nloss: tensor(0.6912, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6286, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6055, grad_fn=<NllLossBackward0>)\n\n\nepoch,  1\nloss: tensor(0.6428, grad_fn=<NllLossBackward0>)\nloss: tensor(0.7088, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6326, grad_fn=<NllLossBackward0>)\n\n\nepoch,  2\nloss: tensor(0.6037, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6602, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6184, grad_fn=<NllLossBackward0>)\n\n\nepoch,  3\nloss: tensor(0.6119, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6393, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6746, grad_fn=<NllLossBackward0>)\n\n\nepoch,  4\nloss: tensor(0.5922, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6318, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6209, grad_fn=<NllLossBackward0>)\n\n\nepoch,  5\nloss: tensor(0.6013, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6198, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6034, grad_fn=<NllLossBackward0>)\n\n\nepoch,  6\nloss: tensor(0.5819, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5925, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5183, grad_fn=<NllLossBackward0>)\n\n\nepoch,  7\nloss: tensor(0.5936, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5483, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3431, grad_fn=<NllLossBackward0>)\n\n\nepoch,  8\nloss: tensor(0.5028, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6244, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6855, grad_fn=<NllLossBackward0>)\n\n\nepoch,  9\nloss: tensor(0.5573, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5257, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6451, grad_fn=<NllLossBackward0>)\n\n\nepoch,  10\nloss: tensor(0.6282, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4379, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5905, grad_fn=<NllLossBackward0>)\n\n\nepoch,  11\nloss: tensor(0.5818, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5794, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3546, grad_fn=<NllLossBackward0>)\n\n\nepoch,  12\nloss: tensor(0.5386, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4832, grad_fn=<NllLossBackward0>)\nloss: tensor(0.7243, grad_fn=<NllLossBackward0>)\n\n\nepoch,  13\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5235, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5420, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5907, grad_fn=<NllLossBackward0>)\n\n\nepoch,  14\nloss: tensor(0.5518, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4627, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5921, grad_fn=<NllLossBackward0>)\n\n\nepoch,  15\nloss: tensor(0.5442, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5250, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3748, grad_fn=<NllLossBackward0>)\n\n\nepoch,  16\nloss: tensor(0.4785, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5645, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5220, grad_fn=<NllLossBackward0>)\n\n\nepoch,  17\nloss: tensor(0.5006, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5303, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5036, grad_fn=<NllLossBackward0>)\n\n\nepoch,  18\nloss: tensor(0.5017, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5867, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4477, grad_fn=<NllLossBackward0>)\n\n\nepoch,  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5912, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4766, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4270, grad_fn=<NllLossBackward0>)\n\n\nepoch,  20\nloss: tensor(0.3974, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5418, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6825, grad_fn=<NllLossBackward0>)\n\n\nepoch,  21\nloss: tensor(0.4556, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4778, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6677, grad_fn=<NllLossBackward0>)\n\n\nepoch,  22\nloss: tensor(0.5775, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4327, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5494, grad_fn=<NllLossBackward0>)\n\n\nepoch,  23\nloss: tensor(0.5734, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4594, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5951, grad_fn=<NllLossBackward0>)\n\n\nepoch,  24\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4698, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4887, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6612, grad_fn=<NllLossBackward0>)\n\n\nepoch,  25\nloss: tensor(0.4311, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5418, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5330, grad_fn=<NllLossBackward0>)\n\n\nepoch,  26\nloss: tensor(0.5309, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4635, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5192, grad_fn=<NllLossBackward0>)\n\n\nepoch,  27\nloss: tensor(0.6150, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4810, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5670, grad_fn=<NllLossBackward0>)\n\n\nepoch,  28\nloss: tensor(0.5280, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4822, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4767, grad_fn=<NllLossBackward0>)\n\n\nepoch,  29\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4996, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5282, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4370, grad_fn=<NllLossBackward0>)\n\n\nepoch,  30\nloss: tensor(0.5111, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5176, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5865, grad_fn=<NllLossBackward0>)\n\n\nepoch,  31\nloss: tensor(0.4990, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5077, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3585, grad_fn=<NllLossBackward0>)\n\n\nepoch,  32\nloss: tensor(0.5088, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5204, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5297, grad_fn=<NllLossBackward0>)\n\n\nepoch,  33\nloss: tensor(0.5458, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5049, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4838, grad_fn=<NllLossBackward0>)\n\n\nepoch,  34\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5510, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5124, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4359, grad_fn=<NllLossBackward0>)\n\n\nepoch,  35\nloss: tensor(0.4028, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5295, grad_fn=<NllLossBackward0>)\nloss: tensor(0.8096, grad_fn=<NllLossBackward0>)\n\n\nepoch,  36\nloss: tensor(0.4529, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5106, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5813, grad_fn=<NllLossBackward0>)\n\n\nepoch,  37\nloss: tensor(0.5750, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4958, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4284, grad_fn=<NllLossBackward0>)\n\n\nepoch,  38\nloss: tensor(0.4620, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5090, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5816, grad_fn=<NllLossBackward0>)\n\n\nepoch,  39\nloss: tensor(0.5209, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6035, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4007, grad_fn=<NllLossBackward0>)\n\n\nepoch,  40\nloss: tensor(0.4787, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5295, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4577, grad_fn=<NllLossBackward0>)\n\n\nepoch,  41\nloss: tensor(0.5846, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4478, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5274, grad_fn=<NllLossBackward0>)\n\n\nepoch,  42\nloss: tensor(0.5286, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5145, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5099, grad_fn=<NllLossBackward0>)\n\n\nepoch,  43\nloss: tensor(0.4821, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4780, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6243, grad_fn=<NllLossBackward0>)\n\n\nepoch,  44\nloss: tensor(0.5462, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4671, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4422, grad_fn=<NllLossBackward0>)\n\n\nepoch,  45\nloss: tensor(0.5602, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4454, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4870, grad_fn=<NllLossBackward0>)\n\n\nepoch,  46\nloss: tensor(0.5835, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4214, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4349, grad_fn=<NllLossBackward0>)\n\n\nepoch,  47\nloss: tensor(0.4002, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5556, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6734, grad_fn=<NllLossBackward0>)\n\n\nepoch,  48\nloss: tensor(0.5100, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4662, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4670, grad_fn=<NllLossBackward0>)\n\n\nepoch,  49\nloss: tensor(0.4815, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5714, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3554, grad_fn=<NllLossBackward0>)\n\n\nepoch,  50\nloss: tensor(0.4570, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6042, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3330, grad_fn=<NllLossBackward0>)\n\n\nepoch,  51\nloss: tensor(0.4137, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5142, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6742, grad_fn=<NllLossBackward0>)\n\n\nepoch,  52\nloss: tensor(0.4884, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5222, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5637, grad_fn=<NllLossBackward0>)\n\n\nepoch,  53\nloss: tensor(0.5527, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4568, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5473, grad_fn=<NllLossBackward0>)\n\n\nepoch,  54\nloss: tensor(0.5053, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4855, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4547, grad_fn=<NllLossBackward0>)\n\n\nepoch,  55\nloss: tensor(0.4517, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5749, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4030, grad_fn=<NllLossBackward0>)\n\n\nepoch,  56\nloss: tensor(0.4906, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.4906, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5061, grad_fn=<NllLossBackward0>)\n\n\nepoch,  57\nloss: tensor(0.5358, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5172, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3648, grad_fn=<NllLossBackward0>)\n\n\nepoch,  58\nloss: tensor(0.5745, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5007, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.3389, grad_fn=<NllLossBackward0>)\n\n\nepoch,  59\nloss: tensor(0.4813, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5084, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4010, grad_fn=<NllLossBackward0>)\n\n\nepoch,  60\nloss: tensor(0.5950, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4338, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4803, grad_fn=<NllLossBackward0>)\n\n\nepoch,  61\nloss: tensor(0.3765, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5786, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5682, grad_fn=<NllLossBackward0>)\n\n\nepoch,  62\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5277, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4800, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5479, grad_fn=<NllLossBackward0>)\n\n\nepoch,  63\nloss: tensor(0.5294, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4528, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3801, grad_fn=<NllLossBackward0>)\n\n\nepoch,  64\nloss: tensor(0.4909, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5591, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3375, grad_fn=<NllLossBackward0>)\n\n\nepoch,  65\nloss: tensor(0.5446, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4185, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5558, grad_fn=<NllLossBackward0>)\n\n\nepoch,  66\nloss: tensor(0.4290, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5390, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6939, grad_fn=<NllLossBackward0>)\n\n\nepoch,  67\nloss: tensor(0.4992, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4778, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3571, grad_fn=<NllLossBackward0>)\n\n\nepoch,  68\nloss: tensor(0.5648, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4688, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4050, grad_fn=<NllLossBackward0>)\n\n\nepoch,  69\nloss: tensor(0.4718, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4636, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6615, grad_fn=<NllLossBackward0>)\n\n\nepoch,  70\nloss: tensor(0.4936, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4650, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5942, grad_fn=<NllLossBackward0>)\n\n\nepoch,  71\nloss: tensor(0.4463, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5032, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4868, grad_fn=<NllLossBackward0>)\n\n\nepoch,  72\nloss: tensor(0.4523, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4777, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5947, grad_fn=<NllLossBackward0>)\n\n\nepoch,  73\nloss: tensor(0.5099, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4539, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5431, grad_fn=<NllLossBackward0>)\n\n\nepoch,  74\nloss: tensor(0.5018, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5316, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4292, grad_fn=<NllLossBackward0>)\n\n\nepoch,  75\nloss: tensor(0.5234, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4596, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4910, grad_fn=<NllLossBackward0>)\n\n\nepoch,  76\nloss: tensor(0.5089, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4461, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5361, grad_fn=<NllLossBackward0>)\n\n\nepoch,  77\nloss: tensor(0.5769, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5279, grad_fn=<NllLossBackward0>)\nloss: tensor(0.2862, grad_fn=<NllLossBackward0>)\n\n\nepoch,  78\nloss: tensor(0.4802, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4379, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6622, grad_fn=<NllLossBackward0>)\n\n\nepoch,  79\nloss: tensor(0.4688, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5109, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4570, grad_fn=<NllLossBackward0>)\n\n\nepoch,  80\nloss: tensor(0.5661, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3575, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6912, grad_fn=<NllLossBackward0>)\n\n\nepoch,  81\nloss: tensor(0.4650, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4978, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4720, grad_fn=<NllLossBackward0>)\n\n\nepoch,  82\nloss: tensor(0.5243, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3950, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6568, grad_fn=<NllLossBackward0>)\n\n\nepoch,  83\nloss: tensor(0.5554, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4409, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3930, grad_fn=<NllLossBackward0>)\n\n\nepoch,  84\nloss: tensor(0.4425, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5177, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4802, grad_fn=<NllLossBackward0>)\n\n\nepoch,  85\nloss: tensor(0.4200, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4993, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5889, grad_fn=<NllLossBackward0>)\n\n\nepoch,  86\nloss: tensor(0.3875, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5205, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5923, grad_fn=<NllLossBackward0>)\n\n\nepoch,  87\nloss: tensor(0.5238, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4350, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5666, grad_fn=<NllLossBackward0>)\n\n\nepoch,  88\nloss: tensor(0.4325, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4751, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7038, grad_fn=<NllLossBackward0>)\n\n\nepoch,  89\nloss: tensor(0.4786, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4811, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4445, grad_fn=<NllLossBackward0>)\n\n\nepoch,  90\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5556, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4276, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5124, grad_fn=<NllLossBackward0>)\n\n\nepoch,  91\nloss: tensor(0.4386, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5401, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4856, grad_fn=<NllLossBackward0>)\n\n\nepoch,  92\nloss: tensor(0.5261, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5047, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4374, grad_fn=<NllLossBackward0>)\n\n\nepoch,  93\nloss: tensor(0.5780, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3930, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4429, grad_fn=<NllLossBackward0>)\n\n\nepoch,  94\nloss: tensor(0.4316, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4901, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5713, grad_fn=<NllLossBackward0>)\n\n\nepoch,  95\nloss: tensor(0.4664, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4764, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4591, grad_fn=<NllLossBackward0>)\n\n\nepoch,  96\nloss: tensor(0.4686, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5024, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5045, grad_fn=<NllLossBackward0>)\n\n\nepoch,  97\nloss: tensor(0.5027, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4564, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3775, grad_fn=<NllLossBackward0>)\n\n\nepoch,  98\nloss: tensor(0.4329, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5243, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3194, grad_fn=<NllLossBackward0>)\n\n\nepoch,  99\nloss: tensor(0.5147, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4654, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3467, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# web gcn 输出\n",
    "# -*- coding: utf-8 -*-\n",
    "from model.GNN_1 import *\n",
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data.load_data import load_data\n",
    "from torch_geometric.data import Data\n",
    "import random\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = TUDataset('data/TUDataset', name = 'MUTAG')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Datas = []\n",
    "# for i, i_mol_graph in enumerate(list_mol_graph):\n",
    "#     # print(i_mol_graph)\n",
    "#     e_index = torch.tensor([np.concatenate((i_mol_graph.start_indices, i_mol_graph.end_indices), axis=0),\n",
    "#                             np.concatenate((i_mol_graph.end_indices, i_mol_graph.start_indices), axis=0)]).long()\n",
    "#     nodes_x = torch.tensor(i_mol_graph.atom_features).float()\n",
    "#     e_attr = torch.tensor(np.concatenate((i_mol_graph.bond_features, i_mol_graph.bond_features), axis=0)).float()\n",
    "#     y = torch.tensor(properties[i]).float()  # normalize_prop(torch.tensor(properties[i]).float())\n",
    "#     datai = Data(x=nodes_x, edge_index=e_index, edge_attr=e_attr, y=y)\n",
    "#     Datas.append(datai)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset = dataset[150:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "model = GCN_cls(hidden_channels=64, Num_node_features=dataset.num_node_features, num_classes=dataset.num_classes)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nepoch,  0\nloss: tensor(0.6912, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6286, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6055, grad_fn=<NllLossBackward0>)\n\n\nepoch,  1\nloss: tensor(0.6428, grad_fn=<NllLossBackward0>)\nloss: tensor(0.7088, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6326, grad_fn=<NllLossBackward0>)\n\n\nepoch,  2\nloss: tensor(0.6037, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6602, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6184, grad_fn=<NllLossBackward0>)\n\n\nepoch,  3\nloss: tensor(0.6119, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6393, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6746, grad_fn=<NllLossBackward0>)\n\n\nepoch,  4\nloss: tensor(0.5922, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6318, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6209, grad_fn=<NllLossBackward0>)\n\n\nepoch,  5\nloss: tensor(0.6013, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6198, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6034, grad_fn=<NllLossBackward0>)\n\n\nepoch,  6\nloss: tensor(0.5819, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5925, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5183, grad_fn=<NllLossBackward0>)\n\n\nepoch,  7\nloss: tensor(0.5936, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5483, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3431, grad_fn=<NllLossBackward0>)\n\n\nepoch,  8\nloss: tensor(0.5028, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6244, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6855, grad_fn=<NllLossBackward0>)\n\n\nepoch,  9\nloss: tensor(0.5573, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5257, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6451, grad_fn=<NllLossBackward0>)\n\n\nepoch,  10\nloss: tensor(0.6282, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4379, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5905, grad_fn=<NllLossBackward0>)\n\n\nepoch,  11\nloss: tensor(0.5818, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5794, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3546, grad_fn=<NllLossBackward0>)\n\n\nepoch,  12\nloss: tensor(0.5386, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4832, grad_fn=<NllLossBackward0>)\nloss: tensor(0.7243, grad_fn=<NllLossBackward0>)\n\n\nepoch,  13\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5235, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5420, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5907, grad_fn=<NllLossBackward0>)\n\n\nepoch,  14\nloss: tensor(0.5518, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4627, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5921, grad_fn=<NllLossBackward0>)\n\n\nepoch,  15\nloss: tensor(0.5442, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5250, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3748, grad_fn=<NllLossBackward0>)\n\n\nepoch,  16\nloss: tensor(0.4785, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5645, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5220, grad_fn=<NllLossBackward0>)\n\n\nepoch,  17\nloss: tensor(0.5006, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5303, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5036, grad_fn=<NllLossBackward0>)\n\n\nepoch,  18\nloss: tensor(0.5017, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5867, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4477, grad_fn=<NllLossBackward0>)\n\n\nepoch,  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5912, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4766, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4270, grad_fn=<NllLossBackward0>)\n\n\nepoch,  20\nloss: tensor(0.3974, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5418, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6825, grad_fn=<NllLossBackward0>)\n\n\nepoch,  21\nloss: tensor(0.4556, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4778, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6677, grad_fn=<NllLossBackward0>)\n\n\nepoch,  22\nloss: tensor(0.5775, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4327, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5494, grad_fn=<NllLossBackward0>)\n\n\nepoch,  23\nloss: tensor(0.5734, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4594, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5951, grad_fn=<NllLossBackward0>)\n\n\nepoch,  24\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4698, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4887, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6612, grad_fn=<NllLossBackward0>)\n\n\nepoch,  25\nloss: tensor(0.4311, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5418, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5330, grad_fn=<NllLossBackward0>)\n\n\nepoch,  26\nloss: tensor(0.5309, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4635, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5192, grad_fn=<NllLossBackward0>)\n\n\nepoch,  27\nloss: tensor(0.6150, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4810, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5670, grad_fn=<NllLossBackward0>)\n\n\nepoch,  28\nloss: tensor(0.5280, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4822, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4767, grad_fn=<NllLossBackward0>)\n\n\nepoch,  29\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4996, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5282, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4370, grad_fn=<NllLossBackward0>)\n\n\nepoch,  30\nloss: tensor(0.5111, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5176, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5865, grad_fn=<NllLossBackward0>)\n\n\nepoch,  31\nloss: tensor(0.4990, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5077, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3585, grad_fn=<NllLossBackward0>)\n\n\nepoch,  32\nloss: tensor(0.5088, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5204, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5297, grad_fn=<NllLossBackward0>)\n\n\nepoch,  33\nloss: tensor(0.5458, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5049, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4838, grad_fn=<NllLossBackward0>)\n\n\nepoch,  34\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5510, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5124, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4359, grad_fn=<NllLossBackward0>)\n\n\nepoch,  35\nloss: tensor(0.4028, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5295, grad_fn=<NllLossBackward0>)\nloss: tensor(0.8096, grad_fn=<NllLossBackward0>)\n\n\nepoch,  36\nloss: tensor(0.4529, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5106, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5813, grad_fn=<NllLossBackward0>)\n\n\nepoch,  37\nloss: tensor(0.5750, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4958, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4284, grad_fn=<NllLossBackward0>)\n\n\nepoch,  38\nloss: tensor(0.4620, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5090, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5816, grad_fn=<NllLossBackward0>)\n\n\nepoch,  39\nloss: tensor(0.5209, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6035, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4007, grad_fn=<NllLossBackward0>)\n\n\nepoch,  40\nloss: tensor(0.4787, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5295, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4577, grad_fn=<NllLossBackward0>)\n\n\nepoch,  41\nloss: tensor(0.5846, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4478, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5274, grad_fn=<NllLossBackward0>)\n\n\nepoch,  42\nloss: tensor(0.5286, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5145, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5099, grad_fn=<NllLossBackward0>)\n\n\nepoch,  43\nloss: tensor(0.4821, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4780, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6243, grad_fn=<NllLossBackward0>)\n\n\nepoch,  44\nloss: tensor(0.5462, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4671, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4422, grad_fn=<NllLossBackward0>)\n\n\nepoch,  45\nloss: tensor(0.5602, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4454, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4870, grad_fn=<NllLossBackward0>)\n\n\nepoch,  46\nloss: tensor(0.5835, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4214, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4349, grad_fn=<NllLossBackward0>)\n\n\nepoch,  47\nloss: tensor(0.4002, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5556, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6734, grad_fn=<NllLossBackward0>)\n\n\nepoch,  48\nloss: tensor(0.5100, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4662, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4670, grad_fn=<NllLossBackward0>)\n\n\nepoch,  49\nloss: tensor(0.4815, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5714, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3554, grad_fn=<NllLossBackward0>)\n\n\nepoch,  50\nloss: tensor(0.4570, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6042, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3330, grad_fn=<NllLossBackward0>)\n\n\nepoch,  51\nloss: tensor(0.4137, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5142, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6742, grad_fn=<NllLossBackward0>)\n\n\nepoch,  52\nloss: tensor(0.4884, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5222, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5637, grad_fn=<NllLossBackward0>)\n\n\nepoch,  53\nloss: tensor(0.5527, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4568, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5473, grad_fn=<NllLossBackward0>)\n\n\nepoch,  54\nloss: tensor(0.5053, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4855, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4547, grad_fn=<NllLossBackward0>)\n\n\nepoch,  55\nloss: tensor(0.4517, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5749, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4030, grad_fn=<NllLossBackward0>)\n\n\nepoch,  56\nloss: tensor(0.4906, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.4906, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5061, grad_fn=<NllLossBackward0>)\n\n\nepoch,  57\nloss: tensor(0.5358, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5172, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3648, grad_fn=<NllLossBackward0>)\n\n\nepoch,  58\nloss: tensor(0.5745, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5007, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.3389, grad_fn=<NllLossBackward0>)\n\n\nepoch,  59\nloss: tensor(0.4813, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5084, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4010, grad_fn=<NllLossBackward0>)\n\n\nepoch,  60\nloss: tensor(0.5950, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4338, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4803, grad_fn=<NllLossBackward0>)\n\n\nepoch,  61\nloss: tensor(0.3765, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5786, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5682, grad_fn=<NllLossBackward0>)\n\n\nepoch,  62\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5277, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4800, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5479, grad_fn=<NllLossBackward0>)\n\n\nepoch,  63\nloss: tensor(0.5294, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4528, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3801, grad_fn=<NllLossBackward0>)\n\n\nepoch,  64\nloss: tensor(0.4909, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5591, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3375, grad_fn=<NllLossBackward0>)\n\n\nepoch,  65\nloss: tensor(0.5446, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4185, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5558, grad_fn=<NllLossBackward0>)\n\n\nepoch,  66\nloss: tensor(0.4290, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5390, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6939, grad_fn=<NllLossBackward0>)\n\n\nepoch,  67\nloss: tensor(0.4992, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4778, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3571, grad_fn=<NllLossBackward0>)\n\n\nepoch,  68\nloss: tensor(0.5648, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4688, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4050, grad_fn=<NllLossBackward0>)\n\n\nepoch,  69\nloss: tensor(0.4718, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4636, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6615, grad_fn=<NllLossBackward0>)\n\n\nepoch,  70\nloss: tensor(0.4936, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4650, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5942, grad_fn=<NllLossBackward0>)\n\n\nepoch,  71\nloss: tensor(0.4463, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5032, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4868, grad_fn=<NllLossBackward0>)\n\n\nepoch,  72\nloss: tensor(0.4523, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4777, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5947, grad_fn=<NllLossBackward0>)\n\n\nepoch,  73\nloss: tensor(0.5099, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4539, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5431, grad_fn=<NllLossBackward0>)\n\n\nepoch,  74\nloss: tensor(0.5018, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5316, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4292, grad_fn=<NllLossBackward0>)\n\n\nepoch,  75\nloss: tensor(0.5234, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4596, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4910, grad_fn=<NllLossBackward0>)\n\n\nepoch,  76\nloss: tensor(0.5089, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4461, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5361, grad_fn=<NllLossBackward0>)\n\n\nepoch,  77\nloss: tensor(0.5769, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5279, grad_fn=<NllLossBackward0>)\nloss: tensor(0.2862, grad_fn=<NllLossBackward0>)\n\n\nepoch,  78\nloss: tensor(0.4802, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4379, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6622, grad_fn=<NllLossBackward0>)\n\n\nepoch,  79\nloss: tensor(0.4688, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5109, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4570, grad_fn=<NllLossBackward0>)\n\n\nepoch,  80\nloss: tensor(0.5661, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3575, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6912, grad_fn=<NllLossBackward0>)\n\n\nepoch,  81\nloss: tensor(0.4650, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4978, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4720, grad_fn=<NllLossBackward0>)\n\n\nepoch,  82\nloss: tensor(0.5243, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3950, grad_fn=<NllLossBackward0>)\nloss: tensor(0.6568, grad_fn=<NllLossBackward0>)\n\n\nepoch,  83\nloss: tensor(0.5554, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4409, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3930, grad_fn=<NllLossBackward0>)\n\n\nepoch,  84\nloss: tensor(0.4425, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5177, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4802, grad_fn=<NllLossBackward0>)\n\n\nepoch,  85\nloss: tensor(0.4200, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4993, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5889, grad_fn=<NllLossBackward0>)\n\n\nepoch,  86\nloss: tensor(0.3875, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5205, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5923, grad_fn=<NllLossBackward0>)\n\n\nepoch,  87\nloss: tensor(0.5238, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4350, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5666, grad_fn=<NllLossBackward0>)\n\n\nepoch,  88\nloss: tensor(0.4325, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4751, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7038, grad_fn=<NllLossBackward0>)\n\n\nepoch,  89\nloss: tensor(0.4786, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4811, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4445, grad_fn=<NllLossBackward0>)\n\n\nepoch,  90\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5556, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4276, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5124, grad_fn=<NllLossBackward0>)\n\n\nepoch,  91\nloss: tensor(0.4386, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5401, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4856, grad_fn=<NllLossBackward0>)\n\n\nepoch,  92\nloss: tensor(0.5261, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5047, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4374, grad_fn=<NllLossBackward0>)\n\n\nepoch,  93\nloss: tensor(0.5780, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3930, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4429, grad_fn=<NllLossBackward0>)\n\n\nepoch,  94\nloss: tensor(0.4316, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4901, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5713, grad_fn=<NllLossBackward0>)\n\n\nepoch,  95\nloss: tensor(0.4664, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4764, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4591, grad_fn=<NllLossBackward0>)\n\n\nepoch,  96\nloss: tensor(0.4686, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5024, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5045, grad_fn=<NllLossBackward0>)\n\n\nepoch,  97\nloss: tensor(0.5027, grad_fn=<NllLossBackward0>)\nloss: tensor(0.4564, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3775, grad_fn=<NllLossBackward0>)\n\n\nepoch,  98\nloss: tensor(0.4329, grad_fn=<NllLossBackward0>)\nloss: tensor(0.5243, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3194, grad_fn=<NllLossBackward0>)\n\n\nepoch,  99\nloss: tensor(0.5147, grad_fn=<NllLossBackward0>)\nloss: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4654, grad_fn=<NllLossBackward0>)\nloss: tensor(0.3467, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cnt=0\n",
    "for i in range(100):\n",
    "    print('\\n\\nepoch, ',i)\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.x, '\\n',data.edge_index, '\\n',data.batch)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        # print(out[:5])\n",
    "        # print(data.y[:5], '\\n\\n')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('loss:', loss)\n",
    "    # cnt+=1\n",
    "    # if cnt>100:\n",
    "    #     break        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1758,  0.9645],\n        [-1.3752,  1.1595],\n        [-1.2888,  1.0753],\n        [-0.5771,  0.3737],\n        [-1.3625,  1.1468],\n        [ 0.6148, -0.8496],\n        [ 0.4702, -0.7510],\n        [-0.6189,  0.4072],\n        [-0.6957,  0.4612],\n        [-1.5666,  1.3466],\n        [-0.8152,  0.5809],\n        [-1.0452,  0.8320],\n        [ 0.0324, -0.2932],\n        [-0.7716,  0.5697],\n        [ 0.0480, -0.3039],\n        [-1.4316,  1.2140],\n        [-0.1776, -0.0688],\n        [-1.2330,  1.0196],\n        [-0.3011,  0.0781],\n        [ 0.1647, -0.4005],\n        [-0.5247,  0.3027],\n        [-0.0650, -0.1433],\n        [ 0.6552, -0.9307],\n        [-1.1055,  0.8967],\n        [ 0.0233, -0.2835],\n        [-0.3972,  0.1717],\n        [-1.1816,  0.9672],\n        [-0.6076,  0.3729],\n        [-0.9187,  0.7136],\n        [-0.3130,  0.0853],\n        [-1.5666,  1.3466],\n        [-1.4363,  1.2187],\n        [-1.1834,  0.9711],\n        [-1.1292,  0.9138],\n        [-1.4890,  1.2702],\n        [-0.4821,  0.2819],\n        [-0.0651, -0.1671],\n        [-1.1828,  0.9709]], grad_fn=<AddmmBackward0>)\ntensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\ntensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1])\nacc: 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "loader = test_loader\n",
    "model.eval()\n",
    "    \n",
    "correct = 0\n",
    "for data in loader:  # 批遍历测试集数据集。\n",
    "    \n",
    "    out = model(data.x, data.edge_index, data.batch)  # 一次前向传播\n",
    "    print(out)\n",
    "    pred = out.argmax(dim=1)  # 使用概率最高的类别\n",
    "    print(pred)\n",
    "    print(data.y)\n",
    "    # pred = out.argmax(dim=1)  # 使用概率最高的类别\n",
    "    correct += int((pred == data.y).sum())  # 检查真实标签\n",
    "    # print(pred[:20])\n",
    "    # print(data.y[:20], '\\n\\n')\n",
    "    \n",
    "print('acc:',  correct / len(loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 150\nNumber of test graphs: 38\nGCN_cls(\n  (conv1): GCNConv(7, 32)\n  (conv2): GCNConv(32, 32)\n  (conv3): GCNConv(32, 32)\n  (lin): Linear(in_features=32, out_features=7, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        print(out[:5])\n",
    "        print(data.y[:5], '\\n\\n')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for data in loader:  # 批遍历测试集数据集。\n",
    "        out = model(data.x, data.edge_index, data.batch)  # 一次前向传播\n",
    "        pred = out.argmax(dim=1)  # 使用概率最高的类别\n",
    "        correct += int((pred == data.y).sum())  # 检查真实标签\n",
    "        print(pred[:20])\n",
    "        print(data.y[:20], '\\n\\n')\n",
    "        \n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 121):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9162\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "print('\\tLoading Data...')\n",
    "list_mol_graph, properties = load_data('sars')\n",
    "properties = torch.FloatTensor(properties)\n",
    "# exit()\n",
    "# n_mol = len(list_mol_graph)\n",
    "# list_torch_graph = [(\n",
    "#     torch.FloatTensor(mol_graph.atom_features),\n",
    "#     torch.FloatTensor(mol_graph.bond_features),\n",
    "#     mol_graph.start_indices,\n",
    "#     mol_graph.end_indices\n",
    "# ) for mol_graph in list_mol_graph ]\n",
    "\n",
    "print('select...')\n",
    "Datas = []\n",
    "for i_mol_graph, y in zip(list_mol_graph, properties):\n",
    "    # print(y)\n",
    "    if not y[0].isnan():\n",
    "        e_index = torch.tensor([np.concatenate((i_mol_graph.start_indices, i_mol_graph.end_indices), axis=0),\n",
    "                        np.concatenate((i_mol_graph.end_indices, i_mol_graph.start_indices), axis=0)]).long()\n",
    "        nodes_x = torch.tensor(i_mol_graph.atom_features).float()\n",
    "        e_attr = torch.tensor(np.concatenate((i_mol_graph.bond_features , i_mol_graph.bond_features), axis=0)).float()\n",
    "        y =   y[0].long() # normalize_prop(torch.tensor(properties[i]).float())\n",
    "        datai = Data(x = nodes_x, edge_index=e_index, edge_attr=e_attr, y=y)\n",
    "        Datas.append(datai)\n",
    "\n",
    "print(len(Datas))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datas[0].y.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9162, 2620, 7512, 3413, 2049, 2049, 2049, 2049, 7512, 7512, 2620, 2620]\ntensor([nan, nan, 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    }
   ],
   "source": [
    "cnt=[0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "for e in properties:\n",
    "    for i in range(12):\n",
    "        if  not e[i].isnan():                 # e.[0]!='nan':\n",
    "            cnt[i]+=1\n",
    "    \n",
    "    # if  not e[1].isnan():                 # e.[0]!='nan':\n",
    "    #     cnt1+=1\n",
    "    # else:\n",
    "    #     pass\n",
    "        # print(e.tolist()[0])\n",
    "\n",
    "print(cnt)\n",
    "print(properties[0])\n",
    "# properties[0].tolist()[2].isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9162, 2620, 7512, 3413, 2049, 2049, 2049, 2049, 7512, 7512, 2620, 2620]\ntensor([nan, nan, 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.train()\n",
    "# optimizer.zero_grad()\n",
    "# list_pred = []\n",
    "# list_prop = []\n",
    "# for i, (af, bf, us, vs) in enumerate(ltg):\n",
    "#     if USE_CUDA:\n",
    "#         af, bf = af.cuda(), bf.cuda()\n",
    "#     pred = model.forward(af, bf, us, vs)\n",
    "#     list_pred.append(pred)\n",
    "#     list_prop.append(ppts[i].cuda() if USE_CUDA else ppts[i])\n",
    "#     if len(list_pred) >= BATCH_SIZE or i == len(ltg) - 1:\n",
    "#         batch_pred = torch.vstack(list_pred)\n",
    "#         batch_pred = denormalize_prop(batch_pred)\n",
    "#         batch_prop = torch.vstack(list_prop)\n",
    "#         loss = F.mse_loss(batch_pred, batch_prop)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         list_pred.clear()\n",
    "#         list_prop.clear()\n",
    "\n",
    "# exit()\n",
    "# def evaluate(ltg: List[Tuple[torch.Tensor, torch.Tensor, np.ndarray, np.ndarray]], ppts: torch.Tensor) -> float:\n",
    "ltg = train_ltg\n",
    "ppts = train_ppts\n",
    "model.eval()\n",
    "list_pred = []\n",
    "for i, (af, bf, us, vs) in enumerate(ltg):\n",
    "    # if i>5:\n",
    "    #     break\n",
    "    if USE_CUDA:\n",
    "        af, bf = af.cuda(), bf.cuda()\n",
    "    pred = model.forward(af, bf, us, vs)\n",
    "    list_pred.append(pred.cpu().detach())\n",
    "    print('list_pred: \\n', list_pred, '\\n')\n",
    "\n",
    "total_pred = torch.vstack(list_pred)\n",
    "print('total_pred**************: \\n', total_pred, '\\n')\n",
    "total_pred = denormalize_prop(total_pred)\n",
    "rmse = torch.sqrt(F.mse_loss(total_pred, ppts))\n",
    "rmse = float(rmse)\n",
    "# print(f'\\t\\t\\tRMSE----------: {rmse:.4f}')\n",
    "#     return rmse\n",
    "\n",
    "exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
